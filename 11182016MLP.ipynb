{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PIMA Indians Diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataset = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "preg       int64\n",
      "plas       int64\n",
      "pres       int64\n",
      "skin       int64\n",
      "test       int64\n",
      "mass     float64\n",
      "pedi     float64\n",
      "age        int64\n",
      "class      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![title](img/MLP1.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11490cbd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, Y, nb_epoch=150, batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/768 [>.............................] - ETA: 0sacc: 78.91%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "scores = model.evaluate(X,Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Use a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "validation_size = 0.20\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/150\n",
      "614/614 [==============================] - 0s - loss: 0.6869 - acc: 0.5896 - val_loss: 0.6787 - val_acc: 0.6299\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s - loss: 0.6618 - acc: 0.6564 - val_loss: 0.6682 - val_acc: 0.6299\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s - loss: 0.6496 - acc: 0.6596 - val_loss: 0.6483 - val_acc: 0.6364\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s - loss: 0.6378 - acc: 0.6694 - val_loss: 0.6416 - val_acc: 0.6169\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s - loss: 0.6263 - acc: 0.6726 - val_loss: 0.6166 - val_acc: 0.6623\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s - loss: 0.6162 - acc: 0.6808 - val_loss: 0.6315 - val_acc: 0.6364\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s - loss: 0.6114 - acc: 0.6645 - val_loss: 0.6068 - val_acc: 0.6688\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s - loss: 0.6143 - acc: 0.6743 - val_loss: 0.6026 - val_acc: 0.7273\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s - loss: 0.5992 - acc: 0.6922 - val_loss: 0.5946 - val_acc: 0.7143\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s - loss: 0.5934 - acc: 0.6743 - val_loss: 0.5938 - val_acc: 0.6818\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s - loss: 0.5983 - acc: 0.6938 - val_loss: 0.6133 - val_acc: 0.6753\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s - loss: 0.5960 - acc: 0.6922 - val_loss: 0.5905 - val_acc: 0.7208\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s - loss: 0.5962 - acc: 0.6889 - val_loss: 0.5845 - val_acc: 0.7078\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s - loss: 0.5905 - acc: 0.6743 - val_loss: 0.6024 - val_acc: 0.7013\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s - loss: 0.5926 - acc: 0.6775 - val_loss: 0.5889 - val_acc: 0.6883\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s - loss: 0.5858 - acc: 0.7003 - val_loss: 0.5797 - val_acc: 0.7208\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s - loss: 0.5826 - acc: 0.6889 - val_loss: 0.5773 - val_acc: 0.7273\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s - loss: 0.5805 - acc: 0.7003 - val_loss: 0.5795 - val_acc: 0.7078\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s - loss: 0.5839 - acc: 0.6873 - val_loss: 0.5924 - val_acc: 0.6818\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s - loss: 0.5799 - acc: 0.6873 - val_loss: 0.5945 - val_acc: 0.6623\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s - loss: 0.5905 - acc: 0.6889 - val_loss: 0.5821 - val_acc: 0.7078\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s - loss: 0.5753 - acc: 0.7020 - val_loss: 0.5658 - val_acc: 0.7338\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s - loss: 0.5827 - acc: 0.6938 - val_loss: 0.5687 - val_acc: 0.7208\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s - loss: 0.5723 - acc: 0.7003 - val_loss: 0.5698 - val_acc: 0.7468\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s - loss: 0.5766 - acc: 0.6808 - val_loss: 0.5713 - val_acc: 0.7403\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s - loss: 0.5714 - acc: 0.7085 - val_loss: 0.5637 - val_acc: 0.7273\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s - loss: 0.5698 - acc: 0.6906 - val_loss: 0.5688 - val_acc: 0.7403\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s - loss: 0.5642 - acc: 0.6954 - val_loss: 0.5843 - val_acc: 0.7078\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s - loss: 0.5712 - acc: 0.7036 - val_loss: 0.5665 - val_acc: 0.7532\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s - loss: 0.5705 - acc: 0.7052 - val_loss: 0.5660 - val_acc: 0.7338\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s - loss: 0.5711 - acc: 0.7003 - val_loss: 0.5604 - val_acc: 0.7338\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s - loss: 0.5625 - acc: 0.7003 - val_loss: 0.5653 - val_acc: 0.7338\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s - loss: 0.5634 - acc: 0.6987 - val_loss: 0.5564 - val_acc: 0.7532\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s - loss: 0.5599 - acc: 0.7052 - val_loss: 0.5637 - val_acc: 0.7403\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s - loss: 0.5594 - acc: 0.7215 - val_loss: 0.5549 - val_acc: 0.7273\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s - loss: 0.5544 - acc: 0.7199 - val_loss: 0.5770 - val_acc: 0.6948\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s - loss: 0.5631 - acc: 0.7199 - val_loss: 0.5546 - val_acc: 0.7403\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s - loss: 0.5572 - acc: 0.7166 - val_loss: 0.5608 - val_acc: 0.7403\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s - loss: 0.5530 - acc: 0.7150 - val_loss: 0.5469 - val_acc: 0.7662\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s - loss: 0.5577 - acc: 0.7134 - val_loss: 0.5456 - val_acc: 0.7403\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s - loss: 0.5534 - acc: 0.6954 - val_loss: 0.5525 - val_acc: 0.7468\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s - loss: 0.5515 - acc: 0.7296 - val_loss: 0.5641 - val_acc: 0.7273\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s - loss: 0.5486 - acc: 0.7248 - val_loss: 0.5728 - val_acc: 0.7208\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s - loss: 0.5553 - acc: 0.7052 - val_loss: 0.5480 - val_acc: 0.7597\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s - loss: 0.5463 - acc: 0.7313 - val_loss: 0.5521 - val_acc: 0.7662\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s - loss: 0.5457 - acc: 0.7296 - val_loss: 0.5425 - val_acc: 0.7403\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s - loss: 0.5456 - acc: 0.7231 - val_loss: 0.5434 - val_acc: 0.7403\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s - loss: 0.5441 - acc: 0.7329 - val_loss: 0.5378 - val_acc: 0.7662\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s - loss: 0.5596 - acc: 0.7150 - val_loss: 0.5360 - val_acc: 0.7597\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s - loss: 0.5363 - acc: 0.7215 - val_loss: 0.5574 - val_acc: 0.7143\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s - loss: 0.5350 - acc: 0.7378 - val_loss: 0.5370 - val_acc: 0.7727\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s - loss: 0.5436 - acc: 0.7264 - val_loss: 0.5327 - val_acc: 0.7662\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s - loss: 0.5335 - acc: 0.7329 - val_loss: 0.5483 - val_acc: 0.7208\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s - loss: 0.5410 - acc: 0.7345 - val_loss: 0.5598 - val_acc: 0.7273\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s - loss: 0.5345 - acc: 0.7443 - val_loss: 0.5336 - val_acc: 0.7403\n",
      "Epoch 56/150\n",
      "614/614 [==============================] - 0s - loss: 0.5349 - acc: 0.7264 - val_loss: 0.5254 - val_acc: 0.7727\n",
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s - loss: 0.5333 - acc: 0.7459 - val_loss: 0.5339 - val_acc: 0.7403\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s - loss: 0.5364 - acc: 0.7394 - val_loss: 0.5269 - val_acc: 0.7922\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s - loss: 0.5255 - acc: 0.7459 - val_loss: 0.5179 - val_acc: 0.7727\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s - loss: 0.5362 - acc: 0.7557 - val_loss: 0.5262 - val_acc: 0.7987\n",
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s - loss: 0.5261 - acc: 0.7476 - val_loss: 0.5264 - val_acc: 0.7468\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s - loss: 0.5247 - acc: 0.7541 - val_loss: 0.5291 - val_acc: 0.7792\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s - loss: 0.5206 - acc: 0.7443 - val_loss: 0.5264 - val_acc: 0.7727\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s - loss: 0.5234 - acc: 0.7394 - val_loss: 0.5292 - val_acc: 0.7792\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s - loss: 0.5169 - acc: 0.7459 - val_loss: 0.5427 - val_acc: 0.7273\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s - loss: 0.5195 - acc: 0.7394 - val_loss: 0.5627 - val_acc: 0.7338\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s - loss: 0.5178 - acc: 0.7476 - val_loss: 0.5191 - val_acc: 0.7792\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s - loss: 0.5191 - acc: 0.7394 - val_loss: 0.5169 - val_acc: 0.7922\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s - loss: 0.5221 - acc: 0.7443 - val_loss: 0.5533 - val_acc: 0.7273\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s - loss: 0.5241 - acc: 0.7459 - val_loss: 0.5130 - val_acc: 0.7987\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s - loss: 0.5176 - acc: 0.7524 - val_loss: 0.5192 - val_acc: 0.7922\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s - loss: 0.5148 - acc: 0.7541 - val_loss: 0.5126 - val_acc: 0.7792\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s - loss: 0.5280 - acc: 0.7264 - val_loss: 0.5108 - val_acc: 0.7922\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s - loss: 0.5255 - acc: 0.7443 - val_loss: 0.5153 - val_acc: 0.7922\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s - loss: 0.5128 - acc: 0.7459 - val_loss: 0.5158 - val_acc: 0.7922\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s - loss: 0.5081 - acc: 0.7394 - val_loss: 0.5207 - val_acc: 0.7597\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s - loss: 0.5071 - acc: 0.7459 - val_loss: 0.5116 - val_acc: 0.7662\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s - loss: 0.5114 - acc: 0.7394 - val_loss: 0.5185 - val_acc: 0.7662\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s - loss: 0.5133 - acc: 0.7378 - val_loss: 0.5062 - val_acc: 0.7987\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s - loss: 0.5084 - acc: 0.7687 - val_loss: 0.5070 - val_acc: 0.7987\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s - loss: 0.5100 - acc: 0.7590 - val_loss: 0.5190 - val_acc: 0.7922\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s - loss: 0.5174 - acc: 0.7313 - val_loss: 0.5092 - val_acc: 0.7597\n",
      "Epoch 83/150\n",
      "614/614 [==============================] - 0s - loss: 0.5007 - acc: 0.7655 - val_loss: 0.5144 - val_acc: 0.7792\n",
      "Epoch 84/150\n",
      "614/614 [==============================] - 0s - loss: 0.5053 - acc: 0.7524 - val_loss: 0.5000 - val_acc: 0.7987\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s - loss: 0.5016 - acc: 0.7459 - val_loss: 0.5164 - val_acc: 0.7662\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s - loss: 0.5067 - acc: 0.7541 - val_loss: 0.4999 - val_acc: 0.7922\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s - loss: 0.4977 - acc: 0.7655 - val_loss: 0.5047 - val_acc: 0.7792\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s - loss: 0.5052 - acc: 0.7524 - val_loss: 0.5034 - val_acc: 0.7922\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s - loss: 0.5075 - acc: 0.7492 - val_loss: 0.5085 - val_acc: 0.7792\n",
      "Epoch 90/150\n",
      "614/614 [==============================] - 0s - loss: 0.4986 - acc: 0.7606 - val_loss: 0.4976 - val_acc: 0.8052\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s - loss: 0.5050 - acc: 0.7492 - val_loss: 0.5002 - val_acc: 0.7792\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s - loss: 0.4965 - acc: 0.7655 - val_loss: 0.5247 - val_acc: 0.7662\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s - loss: 0.4956 - acc: 0.7557 - val_loss: 0.5604 - val_acc: 0.7532\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s - loss: 0.5056 - acc: 0.7557 - val_loss: 0.4927 - val_acc: 0.8052\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s - loss: 0.4943 - acc: 0.7590 - val_loss: 0.4907 - val_acc: 0.7987\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s - loss: 0.5013 - acc: 0.7476 - val_loss: 0.4984 - val_acc: 0.7922\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s - loss: 0.4981 - acc: 0.7476 - val_loss: 0.4912 - val_acc: 0.8052\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s - loss: 0.4985 - acc: 0.7541 - val_loss: 0.4949 - val_acc: 0.7922\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s - loss: 0.5023 - acc: 0.7524 - val_loss: 0.5008 - val_acc: 0.7922\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s - loss: 0.4960 - acc: 0.7752 - val_loss: 0.4899 - val_acc: 0.8052\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s - loss: 0.5041 - acc: 0.7590 - val_loss: 0.4926 - val_acc: 0.7922\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s - loss: 0.4956 - acc: 0.7671 - val_loss: 0.4968 - val_acc: 0.7987\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s - loss: 0.4912 - acc: 0.7736 - val_loss: 0.5101 - val_acc: 0.7662\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s - loss: 0.4921 - acc: 0.7492 - val_loss: 0.4877 - val_acc: 0.7987\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s - loss: 0.4976 - acc: 0.7443 - val_loss: 0.4921 - val_acc: 0.7922\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s - loss: 0.4900 - acc: 0.7638 - val_loss: 0.4885 - val_acc: 0.7987\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s - loss: 0.4866 - acc: 0.7606 - val_loss: 0.5009 - val_acc: 0.7792\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s - loss: 0.4851 - acc: 0.7687 - val_loss: 0.4810 - val_acc: 0.7987\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s - loss: 0.4859 - acc: 0.7541 - val_loss: 0.5078 - val_acc: 0.7662\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s - loss: 0.4993 - acc: 0.7606 - val_loss: 0.4963 - val_acc: 0.7662\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s - loss: 0.4982 - acc: 0.7541 - val_loss: 0.4799 - val_acc: 0.8117\n",
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s - loss: 0.4879 - acc: 0.7622 - val_loss: 0.5014 - val_acc: 0.7727\n",
      "Epoch 113/150\n",
      "614/614 [==============================] - 0s - loss: 0.4945 - acc: 0.7459 - val_loss: 0.5200 - val_acc: 0.7597\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s - loss: 0.4876 - acc: 0.7590 - val_loss: 0.4858 - val_acc: 0.7987\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s - loss: 0.4877 - acc: 0.7573 - val_loss: 0.4907 - val_acc: 0.8182\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s - loss: 0.4886 - acc: 0.7687 - val_loss: 0.4829 - val_acc: 0.7987\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s - loss: 0.4743 - acc: 0.7573 - val_loss: 0.5033 - val_acc: 0.7792\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s - loss: 0.4893 - acc: 0.7573 - val_loss: 0.4800 - val_acc: 0.7987\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s - loss: 0.4860 - acc: 0.7638 - val_loss: 0.4854 - val_acc: 0.8052\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s - loss: 0.4824 - acc: 0.7557 - val_loss: 0.4783 - val_acc: 0.8052\n",
      "Epoch 121/150\n",
      "614/614 [==============================] - 0s - loss: 0.4860 - acc: 0.7622 - val_loss: 0.4801 - val_acc: 0.8182\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - 0s - loss: 0.4795 - acc: 0.7671 - val_loss: 0.4991 - val_acc: 0.7987\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s - loss: 0.4875 - acc: 0.7622 - val_loss: 0.4847 - val_acc: 0.7987\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s - loss: 0.4823 - acc: 0.7622 - val_loss: 0.4842 - val_acc: 0.7987\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s - loss: 0.4802 - acc: 0.7508 - val_loss: 0.4818 - val_acc: 0.8052\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s - loss: 0.4833 - acc: 0.7638 - val_loss: 0.4792 - val_acc: 0.8052\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s - loss: 0.4827 - acc: 0.7655 - val_loss: 0.4817 - val_acc: 0.7922\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s - loss: 0.4776 - acc: 0.7573 - val_loss: 0.4950 - val_acc: 0.7857\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s - loss: 0.4774 - acc: 0.7622 - val_loss: 0.5174 - val_acc: 0.7662\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s - loss: 0.4804 - acc: 0.7622 - val_loss: 0.4789 - val_acc: 0.7857\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s - loss: 0.4741 - acc: 0.7687 - val_loss: 0.4786 - val_acc: 0.8117\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s - loss: 0.4811 - acc: 0.7427 - val_loss: 0.4781 - val_acc: 0.7922\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s - loss: 0.4757 - acc: 0.7622 - val_loss: 0.4763 - val_acc: 0.8052\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s - loss: 0.4827 - acc: 0.7524 - val_loss: 0.4852 - val_acc: 0.7922\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s - loss: 0.4806 - acc: 0.7573 - val_loss: 0.4840 - val_acc: 0.7922\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s - loss: 0.4746 - acc: 0.7785 - val_loss: 0.4733 - val_acc: 0.7987\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s - loss: 0.4782 - acc: 0.7622 - val_loss: 0.4957 - val_acc: 0.7857\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s - loss: 0.4769 - acc: 0.7671 - val_loss: 0.4764 - val_acc: 0.8052\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s - loss: 0.4785 - acc: 0.7704 - val_loss: 0.4821 - val_acc: 0.8117\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s - loss: 0.4703 - acc: 0.7752 - val_loss: 0.4800 - val_acc: 0.8052\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s - loss: 0.4819 - acc: 0.7524 - val_loss: 0.4847 - val_acc: 0.7922\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s - loss: 0.4859 - acc: 0.7410 - val_loss: 0.4951 - val_acc: 0.7857\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s - loss: 0.4788 - acc: 0.7541 - val_loss: 0.4957 - val_acc: 0.7857\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s - loss: 0.4800 - acc: 0.7687 - val_loss: 0.4986 - val_acc: 0.7857\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s - loss: 0.4783 - acc: 0.7557 - val_loss: 0.4963 - val_acc: 0.7662\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s - loss: 0.4742 - acc: 0.7606 - val_loss: 0.4814 - val_acc: 0.8052\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s - loss: 0.4718 - acc: 0.7687 - val_loss: 0.5058 - val_acc: 0.7792\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s - loss: 0.4664 - acc: 0.7590 - val_loss: 0.4778 - val_acc: 0.7857\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s - loss: 0.4709 - acc: 0.7769 - val_loss: 0.4734 - val_acc: 0.8052\n",
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s - loss: 0.4726 - acc: 0.7704 - val_loss: 0.4708 - val_acc: 0.8182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1155a1410>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test,Y_test), nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual k-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define 4-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "cvscores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 70.83%\n",
      "acc: 83.85%\n",
      "acc: 75.00%\n",
      "acc: 70.83%\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, Y):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init= 'uniform' , activation= 'relu' ))\n",
    "    model.add(Dense(8, init= 'uniform' , activation= 'relu' ))\n",
    "    model.add(Dense(1, init= 'uniform' , activation= 'sigmoid' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], nb_epoch=150, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.13% (+/- 5.32%)\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Hyperparameters using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = 0.20\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer= 'rmsprop' , init= 'uniform' ):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init=init, activation= 'relu' ))\n",
    "    model.add(Dense(8, init=init, activation= 'relu' ))\n",
    "    model.add(Dense(1, init=init, activation= 'sigmoid' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer=optimizer, metrics=[ 'accuracy' ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop','adam']\n",
    "init = ['normal','uniform']\n",
    "epochs = np.array([150])\n",
    "batches = np.array([10])\n",
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(rescaledX_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.763844 using {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754073 (0.021914) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.763845 (0.013953) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.762227 (0.007933) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 150, 'batch_size': 10}\n",
      "0.754065 (0.004912) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 150, 'batch_size': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:662: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Iris Flowers Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "5. class:\n",
    "-- Iris Setosa\n",
    "-- Iris Versicolour\n",
    "-- Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['seplen', 'sepwid', 'petlen', 'petwid', 'class']\n",
    "iris = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n",
      "seplen    float64\n",
      "sepwid    float64\n",
      "petlen    float64\n",
      "petwid    float64\n",
      "class      object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seplen</th>\n",
       "      <th>sepwid</th>\n",
       "      <th>petlen</th>\n",
       "      <th>petwid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seplen  sepwid  petlen  petwid        class\n",
       "0     5.1     3.5     1.4     0.2  Iris-setosa\n",
       "1     4.9     3.0     1.4     0.2  Iris-setosa\n",
       "2     4.7     3.2     1.3     0.2  Iris-setosa\n",
       "3     4.6     3.1     1.5     0.2  Iris-setosa\n",
       "4     5.0     3.6     1.4     0.2  Iris-setosa"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(iris.shape)\n",
    "print(iris.dtypes)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = iris.values[:,0:4].astype(float)\n",
    "Y = iris.values[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert int to dummy variables (one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 inputs -> [4 hidden nodes] -> 3 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=4, init= 'normal' , activation= 'relu' ))\n",
    "    model.add(Dense(3, init= 'normal' , activation= 'sigmoid' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute the Model using k-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Sonar Object Classification Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A dataset that describes sonar chirp returns bouncing off different surfaces. \n",
    "- 60 input variables: the strength of the returns at different angles, all continuous, generally range from 0-1\n",
    "- binary classification problem (rocks vs. metal cylinders)\n",
    "- 208 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "#names = ['seplen', 'sepwid', 'petlen', 'petwid', 'class']\n",
    "sonar = pd.read_csv(url,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 61)\n",
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "13    float64\n",
      "14    float64\n",
      "15    float64\n",
      "16    float64\n",
      "17    float64\n",
      "18    float64\n",
      "19    float64\n",
      "20    float64\n",
      "21    float64\n",
      "22    float64\n",
      "23    float64\n",
      "24    float64\n",
      "25    float64\n",
      "26    float64\n",
      "27    float64\n",
      "28    float64\n",
      "29    float64\n",
      "       ...   \n",
      "31    float64\n",
      "32    float64\n",
      "33    float64\n",
      "34    float64\n",
      "35    float64\n",
      "36    float64\n",
      "37    float64\n",
      "38    float64\n",
      "39    float64\n",
      "40    float64\n",
      "41    float64\n",
      "42    float64\n",
      "43    float64\n",
      "44    float64\n",
      "45    float64\n",
      "46    float64\n",
      "47    float64\n",
      "48    float64\n",
      "49    float64\n",
      "50    float64\n",
      "51    float64\n",
      "52    float64\n",
      "53    float64\n",
      "54    float64\n",
      "55    float64\n",
      "56    float64\n",
      "57    float64\n",
      "58    float64\n",
      "59    float64\n",
      "60     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sonar.shape)\n",
    "print(sonar.dtypes)\n",
    "sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sonar.values[:,0:60].astype(float)\n",
    "Y = sonar.values[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'R', 'R', 'R', 'R'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 inputs -> [60 hidden nodes] -> 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, init= 'normal' , activation= 'relu' ))\n",
    "    model.add(Dense(1, init= 'normal' , activation= 'sigmoid' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 81.23% (7.89%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, nb_epoch=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve model performance with data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 84.61% (4.14%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize',StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, nb_epoch=100,batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a smaller network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 inputs -> [30] -> 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_smaller():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, init= 'normal' , activation= 'relu' ))\n",
    "    model.add(Dense(1, init= 'normal' , activation= 'sigmoid' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 85.56% (5.69%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize',StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, nb_epoch=100,batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a larger network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 inputs -> [60 -> 30] -> 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, init= 'normal' , activation= 'relu' ))\n",
    "    model.add(Dense(30, init= 'normal' , activation= 'relu' ))\n",
    "    model.add(Dense(1, init= 'normal' , activation= 'sigmoid' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 85.54% (4.39%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize',StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, nb_epoch=100,batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Dropout and Max Norm Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 inputs (dropout 0.2) -> [60] -> 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dropout1():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.2, input_shape=(60,)))\n",
    "    model.add(Dense(30, init= 'normal' , activation= 'relu', W_constraint=maxnorm(3) ))\n",
    "    model.add(Dense(1, init= 'normal' , activation= 'sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 86.00% (3.58%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize',StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_dropout1, nb_epoch=100,batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 inputs -> [60 (dropout 0.2)] -> 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dropout2():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, init= 'normal' , activation= 'relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, init= 'normal' , activation= 'sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 85.11% (6.53%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize',StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_dropout2, nb_epoch=100,batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
