{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PIMA Indians Diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataset = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "preg       int64\n",
      "plas       int64\n",
      "pres       int64\n",
      "skin       int64\n",
      "test       int64\n",
      "mass     float64\n",
      "pedi     float64\n",
      "age        int64\n",
      "class      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import random\n",
    "random.seed(7)\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=7, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'min_samples_split': array([2, 4, 6, 8]), 'min_impurity_split': array([  1.00000e-05,   1.00000e-06,   1.00000e-07,   1.00000e-08,\n",
       "         1.00000e-09]), 'max_depth': array([2, 3, 4, 5]), 'min_samples_leaf': array([1, 2, 3, 4, 5, 6, 7, 8, 9])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = np.arange(2,6)\n",
    "min_samples_leaf = np.arange(1,10)\n",
    "min_samples_split = np.arange(2,10,2)\n",
    "min_impurity_split = 10.0**-np.arange(5,10)\n",
    "\n",
    "param_grid = dict(max_depth=max_depth,min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split,min_impurity_split=min_impurity_split)\n",
    "model = DecisionTreeClassifier(random_state=seed)\n",
    "scoring = 'roc_auc' \n",
    "num_folds = 4\n",
    "grid = GridSearchCV(cv=num_folds, estimator=model, param_grid=param_grid,scoring=scoring,n_jobs=-1)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788322105318\n",
      "(5, 9, 2, 1.0000000000000001e-05)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.max_depth, grid.best_estimator_.min_samples_leaf, grid.best_estimator_.min_samples_split, grid.best_estimator_.min_impurity_split)\n",
    "dtTunedMaxDepth = grid.best_estimator_.max_depth\n",
    "dtTunedMinSamplesLeaf = grid.best_estimator_.min_samples_leaf\n",
    "dtTunedMinSamplesSplit = grid.best_estimator_.min_samples_split\n",
    "dtTunedMinImpuritySplit = grid.best_estimator_.min_impurity_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bagged Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1.0000000000000001e-05, min_samples_leaf=9,\n",
       "            min_samples_split=2, min_weight_fraction_leaf...0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=7, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': array([100, 200, 300, 400]), 'max_samples': array([ 1. ,  0.9,  0.8,  0.7])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators  = np.arange(100,500,100)\n",
    "max_samples = np.arange(1.0,0.7,-0.1)\n",
    "\n",
    "param_grid = dict(n_estimators =n_estimators ,max_samples=max_samples)\n",
    "bdt_dt = DecisionTreeClassifier(random_state=seed, max_depth=dtTunedMaxDepth,min_samples_leaf=dtTunedMinSamplesLeaf,min_samples_split=dtTunedMinSamplesSplit,min_impurity_split=dtTunedMinImpuritySplit)\n",
    "model = BaggingClassifier(base_estimator=bdt_dt, random_state=seed)\n",
    "scoring = 'roc_auc' \n",
    "num_folds = 4\n",
    "grid = GridSearchCV(cv=num_folds, estimator=model, param_grid=param_grid,scoring=scoring,n_jobs=-1)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822039297929\n",
      "(400, 0.70000000000000007)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_estimators, grid.best_estimator_.max_samples)\n",
    "bdtTunedNEstimators = grid.best_estimator_.n_estimators\n",
    "bdtTunedMaxSamples = grid.best_estimator_.max_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=7,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': array([ 0.8,  0.7,  0.6]), 'min_impurity_split': array([  1.00000e-07,   1.00000e-08]), 'n_estimators': array([ 50,  75, 100, 125]), 'max_depth': array([2, 3, 4]), 'min_samples_leaf': array([1, 3, 5])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators  = np.arange(50,150,25)\n",
    "max_features = np.arange(0.8,0.6,-0.1)\n",
    "max_depth = np.arange(2,5)\n",
    "min_samples_leaf = np.arange(1,6,2)\n",
    "min_impurity_split = 10.0**-np.arange(7,9)\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators,\n",
    "                  max_features=max_features, \n",
    "                  max_depth=max_depth, \n",
    "                  min_samples_leaf=min_samples_leaf,\n",
    "                  min_impurity_split=min_impurity_split)\n",
    "model = RandomForestClassifier(random_state=seed)\n",
    "scoring = 'roc_auc' \n",
    "num_folds = 4\n",
    "grid = GridSearchCV(cv=num_folds, estimator=model, param_grid=param_grid,scoring=scoring,n_jobs=-1)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827291561066\n",
      "(125, 0.70000000000000007, 4, 5, 9.9999999999999995e-08)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_estimators, \n",
    "      grid.best_estimator_.max_features,\n",
    "      grid.best_estimator_.max_depth,\n",
    "      grid.best_estimator_.min_samples_leaf,\n",
    "      grid.best_estimator_.min_impurity_split)\n",
    "rfTunedNEstimators = grid.best_estimator_.n_estimators\n",
    "rfTunedMaxFeatures = grid.best_estimator_.max_features\n",
    "rfTunedMaxDepth = grid.best_estimator_.max_depth\n",
    "rfTunedMinSamplesLeaf = grid.best_estimator_.min_samples_leaf\n",
    "rfTunedMinImpuritySplit = grid.best_estimator_.min_impurity_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=7,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': array([ 0.8,  0.7,  0.6]), 'min_impurity_split': array([  1.00000e-07,   1.00000e-08]), 'n_estimators': array([ 50,  75, 100, 125]), 'max_depth': array([2, 3, 4]), 'min_samples_leaf': array([1, 3, 5])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators  = np.arange(50,150,25)\n",
    "max_features = np.arange(0.8,0.6,-0.1)\n",
    "max_depth = np.arange(2,5)\n",
    "min_samples_leaf = np.arange(1,6,2)\n",
    "min_impurity_split = 10.0**-np.arange(7,9)\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators,\n",
    "                  max_features=max_features, \n",
    "                  max_depth=max_depth, \n",
    "                  min_samples_leaf=min_samples_leaf,\n",
    "                  min_impurity_split=min_impurity_split)\n",
    "model = ExtraTreesClassifier(random_state=seed)\n",
    "scoring = 'roc_auc' \n",
    "num_folds = 4\n",
    "grid = GridSearchCV(cv=num_folds, estimator=model, param_grid=param_grid,scoring=scoring,n_jobs=-1)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829275263608\n",
      "(100, 0.70000000000000007, 3, 3, 9.9999999999999995e-08)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_estimators, \n",
    "      grid.best_estimator_.max_features,\n",
    "      grid.best_estimator_.max_depth,\n",
    "      grid.best_estimator_.min_samples_leaf,\n",
    "      grid.best_estimator_.min_impurity_split)\n",
    "etTunedNEstimators = grid.best_estimator_.n_estimators\n",
    "etTunedMaxFeatures = grid.best_estimator_.max_features\n",
    "etTunedMaxDepth = grid.best_estimator_.max_depth\n",
    "etTunedMinSamplesLeaf = grid.best_estimator_.min_samples_leaf\n",
    "etTunedMinImpuritySplit = grid.best_estimator_.min_impurity_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=7, splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=7),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': array([ 50,  75, 100, 125]), 'learning_rate': array([ 1.  ,  1.25,  1.5 ,  1.75]), 'base_estimator__max_depth': array([2, 3, 4]), 'base_estimator__min_samples_leaf': array([1, 2, 3, 4, 5]), 'base_estimator__min_impurity_split': array([  1.00000e-07,   1.00000e-08])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators  = np.arange(50,150,25)\n",
    "learning_rate = np.arange(1,2,0.25)\n",
    "base_estimator__max_depth = np.arange(2,5)\n",
    "base_estimator__min_samples_leaf = np.arange(1,6,1)\n",
    "base_estimator__min_impurity_split = 10.0**-np.arange(7,9)\n",
    "\n",
    "param_grid = dict(n_estimators =n_estimators,\n",
    "                  learning_rate=learning_rate,\n",
    "                  base_estimator__max_depth=base_estimator__max_depth,\n",
    "                  base_estimator__min_samples_leaf=base_estimator__min_samples_leaf,\n",
    "                  base_estimator__min_impurity_split=base_estimator__min_impurity_split)\n",
    "adaboost_dt = DecisionTreeClassifier(random_state=seed)\n",
    "model = AdaBoostClassifier(base_estimator=adaboost_dt, random_state=seed)\n",
    "scoring = 'roc_auc' \n",
    "num_folds = 4\n",
    "grid = GridSearchCV(cv=num_folds, estimator=model, param_grid=param_grid,scoring=scoring,n_jobs=-1)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796931302043\n",
      "(125, 1.25, 4, 2, 9.9999999999999995e-08)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_estimators, \n",
    "      grid.best_estimator_.learning_rate,\n",
    "      grid.best_estimator_.base_estimator.max_depth,\n",
    "      grid.best_estimator_.base_estimator.min_samples_leaf,\n",
    "      grid.best_estimator_.base_estimator.min_impurity_split)\n",
    "adaboostTunedNEstimators = grid.best_estimator_.n_estimators\n",
    "adaboostTunedLearningRate = grid.best_estimator_.learning_rate\n",
    "adaboostTunedMaxDepth = grid.best_estimator_.base_estimator.max_depth\n",
    "adaboostTunedMinSamplesLeaf = grid.best_estimator_.base_estimator.min_samples_leaf\n",
    "adaboostTunedMinImpuritySplit = grid.best_estimator_.base_estimator.min_impurity_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=7,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': array([100, 300]), 'min_impurity_split': array([  1.00000e-07,   1.00000e-08]), 'learning_rate': array([ 0.1  ,  0.01 ,  0.001]), 'max_depth': array([2, 3, 4]), 'min_samples_leaf': array([1, 2, 3, 4, 5])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators  = np.arange(100,500,200)\n",
    "learning_rate = 10.0**-np.arange(1,4)\n",
    "max_depth = np.arange(2,5)\n",
    "min_samples_leaf = np.arange(1,6,1)\n",
    "min_impurity_split = 10.0**-np.arange(7,9)\n",
    "\n",
    "param_grid = dict(n_estimators =n_estimators,\n",
    "                  learning_rate=learning_rate,\n",
    "                  max_depth=max_depth,\n",
    "                  min_samples_leaf=min_samples_leaf,\n",
    "                  min_impurity_split=min_impurity_split)\n",
    "model = GradientBoostingClassifier(random_state=seed)\n",
    "scoring = 'roc_auc' \n",
    "num_folds = 4\n",
    "grid = GridSearchCV(cv=num_folds, estimator=model, param_grid=param_grid,scoring=scoring,n_jobs=-1)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818538452364\n",
      "(300, 0.01, 3, 1, 9.9999999999999995e-08)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_estimators, \n",
    "      grid.best_estimator_.learning_rate,\n",
    "      grid.best_estimator_.max_depth,\n",
    "      grid.best_estimator_.min_samples_leaf,\n",
    "      grid.best_estimator_.min_impurity_split)\n",
    "sgbTunedNEstimators = grid.best_estimator_.n_estimators\n",
    "sgbTunedLearningRate = grid.best_estimator_.learning_rate\n",
    "sgbTunedMaxDepth = grid.best_estimator_.max_depth\n",
    "sgbTunedMinSamplesLeaf = grid.best_estimator_.min_samples_leaf\n",
    "sgbTunedMinImpuritySplit = grid.best_estimator_.min_impurity_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Implementation of Stochastic Gradient Boosting: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "WindowsError",
     "evalue": "[Error -529697949] Windows Error 0xE06D7363",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWindowsError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-72db5f8554a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnum_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m                 for train, test in cv)\n\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\sklearn\\cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1611\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[0;32m--> 439\u001b[0;31m                                     missing=self.missing)\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\core.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'can not initialize DMatrix from {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\core.pyc\u001b[0m in \u001b[0;36mset_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mset\u001b[0m \u001b[0minto\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_float_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\python27\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\core.pyc\u001b[0m in \u001b[0;36mset_float_info\u001b[0;34m(self, field, data)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                                \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                                                \u001b[0mc_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                                                len(data)))\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_uint_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWindowsError\u001b[0m: [Error -529697949] Windows Error 0xE06D7363"
     ]
    }
   ],
   "source": [
    "n_estimators  = [120,160,200]\n",
    "learning_rate = [0.005, 0.05]\n",
    "max_depth = np.arange(2,5)\n",
    "subsample = np.arange(1.0,0.8,-0.1)\n",
    "colsample_bytree = np.arange(1.0,0.8,-0.1)\n",
    "\n",
    "param_grid = dict(n_estimators =n_estimators,\n",
    "                  learning_rate=learning_rate,\n",
    "                  max_depth=max_depth,\n",
    "                  subsample=subsample,\n",
    "                  colsample_bytree=colsample_bytree)\n",
    "model = XGBClassifier(seed=seed,\n",
    "                      objective = \"binary:logistic\",\n",
    "                      nthread = 1,\n",
    "                      silent = True)\n",
    "scoring = 'roc_auc' \n",
    "num_folds = 4\n",
    "grid = GridSearchCV(cv=num_folds, estimator=model, scoring=scoring, param_grid=param_grid,n_jobs=1)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821605459379\n",
      "(120, 0.05, 2, 1.0, 0.90000000000000002)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_estimators, \n",
    "      grid.best_estimator_.learning_rate,\n",
    "      grid.best_estimator_.max_depth,\n",
    "      grid.best_estimator_.subsample,\n",
    "      grid.best_estimator_.colsample_bytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82539015685\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "\n",
    "model1 = BaggingClassifier(base_estimator=bdt_dt, random_state=seed, n_estimators=bdtTunedNEstimators, max_samples=bdtTunedMaxSamples)\n",
    "estimators.append(('bdt',model1))\n",
    "model2 = RandomForestClassifier(random_state=seed, n_estimators=rfTunedNEstimators, max_features=rfTunedMaxFeatures, max_depth=rfTunedMaxDepth, min_samples_leaf=rfTunedMinSamplesLeaf, min_impurity_split=rfTunedMinImpuritySplit)\n",
    "estimators.append(('rf',model2))\n",
    "#model3 = ExtraTreesClassifier(random_state=seed, n_estimators=etTunedNEstimators, max_features=etTunedMaxFeatures, max_depth=etTunedMaxDepth, min_samples_leaf=etTunedMinSamplesLeaf, min_impurity_split=etTunedMinImpuritySplit)\n",
    "#estimators.append(('et',model3))\n",
    "\n",
    "voting = VotingClassifier(estimators,voting='soft')\n",
    "num_folds = 4\n",
    "results = cross_val_score(voting, X_train, Y_train, cv=num_folds, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "\n",
    "adaboost_dt = DecisionTreeClassifier(random_state=seed,\n",
    "                                     max_depth=adaboostTunedMaxDepth,\n",
    "                                     min_samples_leaf=adaboostTunedMinSamplesLeaf,\n",
    "                                     min_impurity_split=adaboostTunedMinImpuritySplit)\n",
    "\n",
    "pipelines = []\n",
    "pipelines.append(('DT', Pipeline([('DT', DecisionTreeClassifier(random_state=seed, max_depth=dtTunedMaxDepth,min_samples_leaf=dtTunedMinSamplesLeaf,min_samples_split=dtTunedMinSamplesSplit,min_impurity_split=dtTunedMinImpuritySplit))])))\n",
    "pipelines.append(('BDT', Pipeline([('BDT', BaggingClassifier(base_estimator=bdt_dt, random_state=seed, n_estimators=bdtTunedNEstimators, max_samples=bdtTunedMaxSamples))])))\n",
    "pipelines.append(('RF', Pipeline([('RF', RandomForestClassifier(random_state=seed, n_estimators=rfTunedNEstimators, max_features=rfTunedMaxFeatures, max_depth=rfTunedMaxDepth, min_samples_leaf=rfTunedMinSamplesLeaf, min_impurity_split=rfTunedMinImpuritySplit))])))\n",
    "pipelines.append(('ET', Pipeline([('ET', ExtraTreesClassifier(random_state=seed, n_estimators=etTunedNEstimators, max_features=etTunedMaxFeatures, max_depth=etTunedMaxDepth, min_samples_leaf=etTunedMinSamplesLeaf, min_impurity_split=etTunedMinImpuritySplit))])))\n",
    "pipelines.append(('AdaBoost', Pipeline([('AdaBoost', AdaBoostClassifier(base_estimator=adaboost_dt, random_state=seed, n_estimators=adaboostTunedNEstimators, learning_rate=adaboostTunedLearningRate))])))\n",
    "pipelines.append(('SGB', Pipeline([('SGB', GradientBoostingClassifier(random_state=seed, n_estimators=sgbTunedNEstimators, learning_rate=sgbTunedLearningRate, max_depth=sgbTunedMaxDepth, min_samples_leaf=sgbTunedMinSamplesLeaf, min_impurity_split=sgbTunedMinImpuritySplit))])))\n",
    "pipelines.append(('Voting', Pipeline([('Voting', voting)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: 0.798426\n",
      "BDT: 0.858383\n",
      "RF: 0.857298\n",
      "ET: 0.872671\n",
      "AdaBoost: 0.830168\n",
      "SGB: 0.843010\n",
      "Voting: 0.859107\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test dataset\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    model.fit(X_train,Y_train)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test,model.predict_proba(X_test)[:,1])\n",
    "    result = auc(fpr,tpr)\n",
    "    results.append(result)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f\" % (name, result)\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
